{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ons_data:\n",
    "    def __init__(self, freq: str, ano_inicio: int, ano_fim: int, idreg: str=None):\n",
    "        self.freq = freq\n",
    "        self.ano_inicio = ano_inicio\n",
    "        self.ano_fim = ano_fim\n",
    "        self.idreg = idreg\n",
    "        self.data = pd.DataFrame()\n",
    "        self.missing_dates = []\n",
    "        self.data_dt_inserted = pd.DataFrame()\n",
    "        self.data_dir = \"../../../data/\"\n",
    "\n",
    "    def read(self) -> pd.DataFrame:\n",
    "        \"\"\"Função para ler arquivos \"csv\" já presentes no diretório de dados.\n",
    "\n",
    "        Args:\n",
    "            idreg (str): sub-região. ['N', 'NE', 'S', 'SE']\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: série de carga elétrica no período entre ano_inicio e ano_fim.\n",
    "        \"\"\"\n",
    "        if self.freq == \"hourly\":\n",
    "            path = \"\".join([self.data_dir,\"hourly_load.csv\"])\n",
    "        elif self.freq == \"daily\":\n",
    "            path = \"\".join([self.data_dir,\"daily_load.csv\"])\n",
    "        df = pd.read_csv(path, sep=\";\", decimal=\",\")\n",
    "        if not self.idreg:\n",
    "            idreg = df[\"id_reg\"].unique()\n",
    "        else:\n",
    "            idreg = [self.idreg]\n",
    "        df = df[df[\"id_reg\"].isin(idreg)]\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        self.data = df\n",
    "        return df\n",
    "\n",
    "    def update(self, printer=False, write=False):\n",
    "\n",
    "        if self.freq == \"hourly\":\n",
    "            url = \"https://ons-dl-prod-opendata.s3.amazonaws.com/dataset/curva-carga-ho/CURVA_CARGA_{}.csv\"\n",
    "            date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "        elif self.freq == \"daily\":\n",
    "            url = \"https://ons-dl-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_{}.csv\"\n",
    "            date_format = \"%Y-%m-%d\"\n",
    "        else:\n",
    "            raise Exception(\"Frequência não reconhecida. Utilize 'hourly' ou 'daily'.\")\n",
    "        get0 = requests.get(url.format(self.ano_inicio)).status_code # verify = False (autenticação)\n",
    "        getn = requests.get(url.format(self.ano_fim)).status_code \n",
    "        if (get0 == 200) and (getn == 200): # 200: página (ano) disponível\n",
    "            # concatenar arquivos de cada ano em um único dataframe\n",
    "            df = pd.DataFrame()\n",
    "            for ano in range(self.ano_inicio, self.ano_fim + 1):\n",
    "                if printer:\n",
    "                    print(f\"Lendo ano {ano}...\")\n",
    "                df2 = pd.read_csv(url.format(ano), sep = \";\")\n",
    "                df = pd.concat([df, df2])\n",
    "            df.columns = [\"id_reg\", \"desc_reg\", \"date\", \"load_mwmed\"]\n",
    "            df.loc[:, \"date\"] = pd.to_datetime(df.loc[:, \"date\"], format = date_format)\n",
    "            df.sort_values(by = \"date\", inplace = True)\n",
    "            df.set_index(\"date\", inplace=True)\n",
    "            if write:\n",
    "                full_path = \"\".join([self.data_dir,f\"{self.freq}_load.csv\"])\n",
    "                df.to_csv(full_path, sep=\";\", decimal=\",\")\n",
    "            self.data = df\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Ano não disponível.\")\n",
    "    \n",
    "    def check_date_column(self, _freq: str, printer=False) -> List[dt.datetime]:\n",
    "        \"\"\"Verifica datas faltantes no intervalo\n",
    "\n",
    "        Args:\n",
    "            _freq (str): frequência da série\n",
    "            printer (bool, optional): informa as datas faltantes em tela. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            List[dt.datetime]: lista de datas faltantes\n",
    "        \"\"\"\n",
    "        date_col = self.data.reset_index()[\"date\"]\n",
    "        missing_dates = pd.date_range(date_col.min(), date_col.max(), freq=_freq).difference(date_col)\n",
    "        missing_list = missing_dates.to_list()\n",
    "        if printer:\n",
    "            print(\"Datas faltantes:\\n\", missing_list)\n",
    "        self.missing_dates = missing_list\n",
    "        return missing_list\n",
    "    \n",
    "    def insert_missing_dates(self, printer=False):\n",
    "        y = self.data.reset_index()\n",
    "        missing = pd.DataFrame(self.missing_dates, columns=[\"date\"])\n",
    "        y = pd.concat([y, missing], ignore_index=True)\n",
    "        y.loc[:,\"date\"] = pd.to_datetime(y.loc[:,\"date\"])\n",
    "        y.set_index(\"date\", inplace=True)\n",
    "        y.sort_index(inplace=True)\n",
    "        faltantes = check_date_column(y.index, _freq='h')\n",
    "        if printer:\n",
    "            print(\"Datas faltantes após transformação:\", faltantes)\n",
    "        self.data_dt_inserted = y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ons_data('daily', 2000, 2023, idreg=\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo ano 2000...\n",
      "Lendo ano 2001...\n",
      "Lendo ano 2002...\n",
      "Lendo ano 2003...\n",
      "Lendo ano 2004...\n",
      "Lendo ano 2005...\n",
      "Lendo ano 2006...\n",
      "Lendo ano 2007...\n",
      "Lendo ano 2008...\n",
      "Lendo ano 2009...\n",
      "Lendo ano 2010...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "No kernel associated with the notebook. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = data.update(write=True, printer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datas faltantes:\n",
      " [Timestamp('2000-10-08 00:00:00'), Timestamp('2001-10-14 00:00:00'), Timestamp('2002-11-03 00:00:00'), Timestamp('2003-10-19 00:00:00'), Timestamp('2004-11-02 00:00:00'), Timestamp('2005-10-16 00:00:00'), Timestamp('2006-11-05 00:00:00'), Timestamp('2007-10-14 00:00:00'), Timestamp('2008-10-19 00:00:00'), Timestamp('2009-10-18 00:00:00'), Timestamp('2010-10-17 00:00:00'), Timestamp('2011-10-16 00:00:00'), Timestamp('2012-10-21 00:00:00'), Timestamp('2013-10-20 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "df2 = data.check_date_column(_freq='d', printer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8924\\474307398.py:89: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y.loc[:,\"date\"] = pd.to_datetime(y.loc[:,\"date\"])\n"
     ]
    }
   ],
   "source": [
    "df3 = data.insert_missing_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2000-10-08 00:00:00'),\n",
       " Timestamp('2001-10-14 00:00:00'),\n",
       " Timestamp('2002-11-03 00:00:00'),\n",
       " Timestamp('2003-10-19 00:00:00'),\n",
       " Timestamp('2004-11-02 00:00:00'),\n",
       " Timestamp('2005-10-16 00:00:00'),\n",
       " Timestamp('2006-11-05 00:00:00'),\n",
       " Timestamp('2007-10-14 00:00:00'),\n",
       " Timestamp('2008-10-19 00:00:00'),\n",
       " Timestamp('2009-10-18 00:00:00'),\n",
       " Timestamp('2010-10-17 00:00:00'),\n",
       " Timestamp('2011-10-16 00:00:00'),\n",
       " Timestamp('2012-10-21 00:00:00'),\n",
       " Timestamp('2013-10-20 00:00:00')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date_column(date_col: List[dt.datetime], _freq: str, printer=False) -> print:\n",
    "\n",
    "    missing_dates = pd.date_range(date_col.min(), date_col.max(), freq=_freq).difference(date_col)\n",
    "    missing_list = missing_dates.to_list()\n",
    "    if printer:\n",
    "        print(\"Datas faltantes:\\n\", missing_list)\n",
    "    return missing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datas faltantes:\n",
      " [Timestamp('2000-10-08 00:00:00'), Timestamp('2001-10-14 00:00:00'), Timestamp('2002-11-03 00:00:00'), Timestamp('2003-10-19 00:00:00'), Timestamp('2004-11-02 00:00:00'), Timestamp('2005-10-16 00:00:00'), Timestamp('2006-11-05 00:00:00'), Timestamp('2007-10-14 00:00:00'), Timestamp('2008-10-19 00:00:00'), Timestamp('2009-10-18 00:00:00'), Timestamp('2010-10-17 00:00:00'), Timestamp('2011-10-16 00:00:00'), Timestamp('2012-10-21 00:00:00'), Timestamp('2013-10-20 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "missing_dates = check_date_column(df.index, _freq=\"h\", printer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_missing_dates(x: pd.DataFrame, missing_dates: list, date_column_name: str):\n",
    "    y = x.reset_index()\n",
    "    missing = pd.DataFrame(missing_dates, columns=[date_column_name])\n",
    "    y = pd.concat([y, missing], ignore_index=True)\n",
    "    y.loc[:,\"date\"] = pd.to_datetime(y.loc[:,\"date\"])\n",
    "    y.set_index(\"date\", inplace=True)\n",
    "    y.sort_index(inplace=True)\n",
    "    faltantes = check_date_column(y.index, _freq='h')\n",
    "    print(\"Datas faltantes após transformação:\", faltantes)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datas faltantes após transformação: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8924\\236898553.py:5: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y.loc[:,\"date\"] = pd.to_datetime(y.loc[:,\"date\"])\n"
     ]
    }
   ],
   "source": [
    "df2 = insert_missing_dates(df, missing_dates=missing_dates, date_column_name=\"date\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
